{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e4a8760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "21deedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = joblib.load(\"svm_model.pk1\")\n",
    "decision_tree_model = joblib.load(\"decision_tree_model.pk1\")\n",
    "random_forest_model = joblib.load(\"random_forest_model.pk1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "11b65852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import sniff,IP,TCP,UDP\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "63ff9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_data = defaultdict(list)\n",
    "flow_start_time = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "00b1c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(packet):\n",
    "    if IP in packet:\n",
    "        ip = packet[IP]\n",
    "        proto = \"tcp\" if TCP in packet else \"udp\" if UDP in packet else \"other\"\n",
    "        src,dst = ip.src, ip.dst\n",
    "        sport = packet.sport if hasattr(packet, \"sport\") else 0\n",
    "        dport = packet.dport if hasattr(packet,\"dport\") else 0\n",
    "        flow_id = f\"{src}-{dst}-{proto}-{sport}-{dport}\"\n",
    "\n",
    "        if flow_id not in flow_start_time:\n",
    "            flow_start_time[flow_id] = packet.time\n",
    "\n",
    "        duration = packet.time - flow_start_time[flow_id]\n",
    "\n",
    "        flags = packet[TCP].flags if TCP in packet else 0\n",
    "        flag_str = str(flags)\n",
    "\n",
    "        flow_data[flow_id].append({\n",
    "            \"timestamp\": packet.time,\n",
    "            \"duration\": duration,\n",
    "            \"protocol_type\": proto,\n",
    "            \"src\": src,\n",
    "            \"dst\": dst,\n",
    "            \"sport\": sport,\n",
    "            \"dport\": dport,\n",
    "            \"flag\": flag_str,\n",
    "            \"wrong_fragment\": 1 if (ip.frag != 0 and ip.flags == 1) else 0,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1d824711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_syn_error(pkt):\n",
    "    return pkt[\"flag\"] in [\"0x4\", \"0x14\", \"0x5\"]\n",
    "\n",
    "def is_rerror(pkt):\n",
    "    return pkt[\"flag\"] in [\"0x4\", \"0x11\", \"0x14\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "5b334154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcp_flag_to_kdd_flag(normalized):\n",
    "    \n",
    "    if normalized == 'S':\n",
    "        return 'S0'\n",
    "    elif normalized == 'SA':\n",
    "        return 'S1'\n",
    "    elif normalized in ['PA', 'A', 'FPA', 'FA']:\n",
    "        return 'SF'\n",
    "    elif normalized == 'RA':\n",
    "        return 'REJ'\n",
    "    elif normalized == 'R':\n",
    "        return 'RSTR'\n",
    "    elif normalized == 'R':  # RST without ACK\n",
    "        return 'RSTO'\n",
    "    elif normalized == 'RS':  # RST + SYN (rare)\n",
    "        return 'RSTOS0'\n",
    "    elif normalized == 'FS':  # SYN + FIN (usually malicious)\n",
    "        return 'SH'\n",
    "    elif normalized == 'S2':  # Custom label, not from Scapy\n",
    "        return 'S2'\n",
    "    elif normalized == 'S3':  # Custom label, not from Scapy\n",
    "        return 'S3'\n",
    "    else:\n",
    "        return 'OTH'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "4cbd15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flow_metrics():\n",
    "\n",
    "    global df\n",
    "    protocols = ['tcp', 'udp']\n",
    "    flags = ['REJ', 'RSTO', 'RSTOS0', 'RSTR', 'S0', 'S1', 'S2', 'S3', 'SF', 'SH']\n",
    "    for flow_id, packets in flow_data.items():\n",
    "        if not packets:\n",
    "            continue\n",
    "\n",
    "        pkt_count = len(packets)\n",
    "        duration = packets[-1][\"timestamp\"] - packets[0][\"timestamp\"]\n",
    "\n",
    "        # Map protocol type\n",
    "        raw_proto = packets[0][\"protocol_type\"]\n",
    "        proto = raw_proto if raw_proto in protocols else 'icmp'\n",
    "        proto_onehot = {f'protocol_type_{p}': int(p == proto) for p in protocols}\n",
    "\n",
    "        last_flag = packets[-1][\"flag\"]\n",
    "        kdd_flag = tcp_flag_to_kdd_flag(last_flag)\n",
    "\n",
    "        # One-hot encoding for flags\n",
    "        flag_onehot = {f'flag_{f}': int(f == kdd_flag) for f in flags}\n",
    "\n",
    "        dst_ip = packets[0][\"dst\"]\n",
    "        dport = packets[0][\"dport\"]\n",
    "\n",
    "        serror_rate = sum(is_syn_error(p) for p in packets) / pkt_count if pkt_count else 0\n",
    "        rerror_rate = sum(is_rerror(p) for p in packets) / pkt_count if pkt_count else 0\n",
    "\n",
    "        host_flows = [\n",
    "            p for fid, pkts in flow_data.items()\n",
    "            if fid.split(\"-\")[1] == dst_ip\n",
    "            for p in pkts\n",
    "        ]\n",
    "        host_pkt_count = len(host_flows)\n",
    "        host_serror_rate = sum(is_syn_error(p) for p in host_flows) / host_pkt_count if host_pkt_count else 0\n",
    "        host_rerror_rate = sum(is_rerror(p) for p in host_flows) / host_pkt_count if host_pkt_count else 0\n",
    "\n",
    "        dst_ports = [p[\"dport\"] for p in packets if \"dport\" in p]\n",
    "        most_common_port = max(set(dst_ports), key=dst_ports.count) if dst_ports else 0\n",
    "        same_srv_count = dst_ports.count(most_common_port)\n",
    "        same_srv_rate = same_srv_count / pkt_count if pkt_count else 0\n",
    "\n",
    "        dst_host_count = sum(1 for fid in flow_data if fid.split(\"-\")[1] == dst_ip)\n",
    "        dst_host_srv_count = sum(\n",
    "            1 for fid in flow_data\n",
    "            if fid.split(\"-\")[1] == dst_ip and fid.split(\"-\")[4] == str(dport)\n",
    "        )\n",
    "        dst_host_same_srv_rate = dst_host_srv_count / dst_host_count if dst_host_count else 0\n",
    "        dst_host_diff_srv_rate = 1.0 - dst_host_same_srv_rate\n",
    "\n",
    "        row = {\n",
    "            \"duration\": duration,\n",
    "            \"wrong_fragment\": sum(p[\"wrong_fragment\"] for p in packets),\n",
    "            \"num_compromised\": 0,\n",
    "            \"count\": pkt_count,\n",
    "            \"serror_rate\": round(serror_rate, 2),\n",
    "            \"srv_serror_rate\": round(serror_rate, 2),\n",
    "            \"rerror_rate\": round(rerror_rate, 2),\n",
    "            \"srv_rerror_rate\": round(rerror_rate, 2),\n",
    "            \"same_srv_rate\": round(same_srv_rate, 2),\n",
    "            \"srv_diff_host_rate\": 0.0,\n",
    "            \"dst_host_count\": dst_host_count,\n",
    "            \"dst_host_srv_count\": dst_host_srv_count,\n",
    "            \"dst_host_same_srv_rate\": round(dst_host_same_srv_rate, 2),\n",
    "            \"dst_host_diff_srv_rate\": round(dst_host_diff_srv_rate, 2),\n",
    "            \"dst_host_serror_rate\": round(host_serror_rate, 2),\n",
    "            \"dst_host_srv_serror_rate\": round(host_serror_rate, 2),\n",
    "        }\n",
    "        row.update(proto_onehot)\n",
    "        row.update(flag_onehot)\n",
    "        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "b9704c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sniffing packets...\n"
     ]
    }
   ],
   "source": [
    "def sniff_packets(timeout=10):\n",
    "    print(\"Sniffing packets...\")\n",
    "    sniff(prn=extract_features, timeout=timeout)\n",
    "sniff_packets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4327236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "96a51551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_majority_vote(pred_lists):\n",
    "    n_samples = len(pred_lists[0])\n",
    "    n_models = len(pred_lists)\n",
    "    majority_votes = []\n",
    "    for i in range(n_samples):\n",
    "        votes = [pred_lists[m][i] for m in range(n_models)]\n",
    "        vote_counts = Counter(votes)\n",
    "        majority_class = vote_counts.most_common(1)[0][0]\n",
    "        majority_votes.append(majority_class)\n",
    "    return np.array(majority_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "c7b39f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(X):\n",
    "    preds1 = svm_model.predict(X).astype(str)\n",
    "    preds2 = decision_tree_model.predict(X).astype(str)\n",
    "    preds3 = random_forest_model.predict(X).astype(str)\n",
    "    print(pd.isnull(preds1).any(), pd.isnull(preds2).any(), pd.isnull(preds3).any())\n",
    "    print(preds1.dtype, preds2.dtype, preds3.dtype)\n",
    "\n",
    "    # Majority voting\n",
    "    preds = np.vstack((preds1, preds2, preds3)).T\n",
    "    majority_vote = custom_majority_vote([preds1, preds2, preds3])\n",
    "    for i, pred in enumerate(majority_vote):\n",
    "        print(f\"Sample {i + 1}: Predicted class = {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "c9479317",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'duration', 'wrong_fragment', 'num_compromised', 'count',\n",
    "    'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
    "    'same_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'protocol_type_tcp', 'protocol_type_udp',\n",
    "    'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0',\n",
    "    'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "5bfc5994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_5844\\3327846966.py:72: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False\n",
      "<U6 <U7 <U7\n",
      "Sample 1: Predicted class = normal\n",
      "Sample 2: Predicted class = normal\n",
      "Sample 3: Predicted class = normal\n",
      "Sample 4: Predicted class = normal\n",
      "Sample 5: Predicted class = normal\n",
      "Sample 6: Predicted class = normal\n",
      "Sample 7: Predicted class = normal\n",
      "Sample 8: Predicted class = normal\n",
      "Sample 9: Predicted class = normal\n",
      "Sample 10: Predicted class = normal\n",
      "Sample 11: Predicted class = normal\n",
      "Sample 12: Predicted class = normal\n",
      "Sample 13: Predicted class = normal\n"
     ]
    }
   ],
   "source": [
    "columns_to_normalize = ['count','duration','dst_host_count','dst_host_srv_count']\n",
    "compute_flow_metrics()\n",
    "scalar = joblib.load('minMaxScalar.pk1')\n",
    "df[columns_to_normalize] = scalar.transform(df[columns_to_normalize])\n",
    "ensemble_predict(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "0715210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duration', 'wrong_fragment', 'num_compromised', 'count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'protocol_type_tcp', 'protocol_type_udp', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "4ea76c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.641538</td>\n",
       "      <td>0.358462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.406506</td>\n",
       "      <td>0.406506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration      count  serror_rate  srv_serror_rate  rerror_rate  \\\n",
       "count  13.000000  13.000000         13.0             13.0         13.0   \n",
       "mean    0.000010   0.008899          0.0              0.0          0.0   \n",
       "std     0.000017   0.017694          0.0              0.0          0.0   \n",
       "min     0.000000   0.000000          0.0              0.0          0.0   \n",
       "25%     0.000000   0.000000          0.0              0.0          0.0   \n",
       "50%     0.000000   0.000000          0.0              0.0          0.0   \n",
       "75%     0.000020   0.009804          0.0              0.0          0.0   \n",
       "max     0.000043   0.054902          0.0              0.0          0.0   \n",
       "\n",
       "       srv_rerror_rate  same_srv_rate  srv_diff_host_rate  dst_host_count  \\\n",
       "count             13.0           13.0                13.0       13.000000   \n",
       "mean               0.0            1.0                 0.0        0.014781   \n",
       "std                0.0            0.0                 0.0        0.008936   \n",
       "min                0.0            1.0                 0.0        0.003922   \n",
       "25%                0.0            1.0                 0.0        0.003922   \n",
       "50%                0.0            1.0                 0.0        0.011765   \n",
       "75%                0.0            1.0                 0.0        0.023529   \n",
       "max                0.0            1.0                 0.0        0.023529   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count           13.000000               13.000000               13.000000   \n",
       "mean             0.006335                0.641538                0.358462   \n",
       "std              0.003411                0.406506                0.406506   \n",
       "min              0.003922                0.170000                0.000000   \n",
       "25%              0.003922                0.170000                0.000000   \n",
       "50%              0.003922                1.000000                0.000000   \n",
       "75%              0.007843                1.000000                0.830000   \n",
       "max              0.011765                1.000000                0.830000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  \n",
       "count                  13.0                      13.0  \n",
       "mean                    0.0                       0.0  \n",
       "std                     0.0                       0.0  \n",
       "min                     0.0                       0.0  \n",
       "25%                     0.0                       0.0  \n",
       "50%                     0.0                       0.0  \n",
       "75%                     0.0                       0.0  \n",
       "max                     0.0                       0.0  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
